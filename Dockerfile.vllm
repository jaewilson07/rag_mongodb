FROM vllm/vllm-openai:latest

# Install git (required for installing transformers from source)
RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*

# vLLM nightly + transformers from git (GLM-4.7-Flash support)
# See: https://huggingface.co/zai-org/GLM-4.7-Flash
#      https://medium.com/@zh.milo/glm-4-7-flash-the-ultimate-2026-guide-to-local-ai-coding-assistant-93a43c3f8db3
RUN pip install -U vllm --pre \
    --index-url https://pypi.org/simple \
    --extra-index-url https://wheels.vllm.ai/nightly

RUN pip install git+https://github.com/huggingface/transformers.git