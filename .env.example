# MongoDB Configuration
# Choose ONE of the following options:

# Option 1: MongoDB Atlas (Managed Cloud - Recommended for Production)
# Get your connection string from MongoDB Atlas after creating a cluster
# Format: mongodb+srv://username:password@cluster.mongodb.net/?appName=YourAppName
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/?appName=YourAppName

# Option 2: Docker Self-Hosted (Development/Testing)
# Use this when running with docker-compose.yml
# MONGODB_URI=mongodb://admin:admin123@atlas-local:27017/rag_db?authSource=admin

# Option 3: Local MongoDB (Self-Hosted without Docker)
# Use this if you have MongoDB running locally without Docker
# MONGODB_URI=mongodb://localhost:27017/rag_db

# Host port for this project's Docker MongoDB (default 7017). Used by sample pre-flight auto-start.
# MONGODB_DOCKER_PORT=7017

MONGODB_DATABASE=rag_db
MONGODB_COLLECTION_DOCUMENTS=documents
MONGODB_COLLECTION_CHUNKS=chunks

# MongoDB Search Indexes
# Atlas: Create these in the Atlas UI
# Docker/Self-Hosted: Auto-created by init_indexes.py (requires MongoDB Enterprise)
MONGODB_VECTOR_INDEX=vector_index
MONGODB_TEXT_INDEX=text_index

# LLM Provider Configuration
# Options: openai, openrouter, ollama, gemini
LLM_PROVIDER=openrouter
LLM_API_KEY=your-api-key-here
LLM_MODEL=anthropic/claude-haiku-4.5
LLM_BASE_URL=https://openrouter.ai/api/v1
# LLM_TEMPERATURE: omit (unset) for models that reject it (OpenRouter, some vLLM). Set e.g. 0.3 for Ollama.

# Embedding Provider Configuration
EMBEDDING_PROVIDER=openai
EMBEDDING_API_KEY=your-openai-api-key-here
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_BASE_URL=https://api.openai.com/v1

# Search Configuration
DEFAULT_MATCH_COUNT=10
MAX_MATCH_COUNT=50
DEFAULT_TEXT_WEIGHT=0.3

# Application Settings
APP_ENV=development
LOG_LEVEL=INFO

# Crawl4AI Settings
CRAWL4AI_WORD_COUNT_THRESHOLD=10
CRAWL4AI_REMOVE_OVERLAY_ELEMENTS=true
CRAWL4AI_REMOVE_BASE64_IMAGES=true
CRAWL4AI_CACHE_MODE=BYPASS
CRAWL4AI_BROWSER_TYPE=chromium
CRAWL4AI_TIMEOUT=30
CRAWL4AI_MAX_DEPTH=2
CRAWL4AI_MAX_CONCURRENT=10
CRAWL4AI_USER_AGENT=
CRAWL4AI_COOKIES=

# Google Drive / Docs Settings
GOOGLE_SERVICE_ACCOUNT_FILE=
GOOGLE_IMPERSONATE_SUBJECT=
GOOGLE_DRIVE_FOLDER_IDS=
GOOGLE_DRIVE_FILE_IDS=
GOOGLE_DOCS_IDS=

# NeuralCursor Second Brain - Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-neo4j-password
NEO4J_DATABASE=neuralcursor

# vLLM Configuration (Claude Code / GLM-4.7)
# Port 11435 = Ollama (11434) + 1 from local-ai-packaged
VLLM_PORT=11435

# NeuralCursor Second Brain - Local LLM Configuration (vLLM)
VLLM_ENABLED=false
VLLM_REASONING_URL=http://localhost:11435
VLLM_EMBEDDING_URL=http://localhost:8001
VLLM_REASONING_MODEL=deepseek-ai/deepseek-coder-33b-instruct
VLLM_EMBEDDING_MODEL=BAAI/bge-m3
