# MongoDB - Episodic Memory

## Overview

The MongoDB module implements the "Episodic Brain" for storing temporal, conversational data and external resources. It handles chat logs, sessions, resources, and provides the data source for the Librarian agent's distillation workflow.

## Core Concepts

### Collections

**sessions**: Conversation sessions with messages
- User-agent conversations
- Project context tracking
- Distillation status flags

**resources**: External reference materials
- YouTube videos, articles, documentation
- Summaries and embeddings
- Tags for categorization

**chunks**: Document chunks from RAG system (inherited)
- Text chunks with embeddings
- Semantic search capability
- Source document references

**documents**: Document metadata (inherited)
- File information
- Processing status
- Chunk references

## File Structure

```
mongodb/
├── __init__.py
└── client.py       # Async MongoDB client with episodic memory operations
```

## Usage Guide

### Initialize Client

```python
from neuralcursor.brain.mongodb.client import MongoDBClient, MongoDBConfig

config = MongoDBConfig(
    uri="mongodb://localhost:27017",
    database="neuralcursor",
    collection_chunks="chunks",
    collection_documents="documents",
    collection_chats="chats",
    collection_resources="resources",
    collection_sessions="sessions"
)

client = MongoDBClient(config)
await client.connect()  # Creates indexes automatically
```

### Save Chat Messages

```python
from neuralcursor.brain.mongodb.client import ChatMessage
from datetime import datetime

# Save a user message
message = ChatMessage(
    role="user",
    content="How do we implement JWT authentication?",
    timestamp=datetime.utcnow(),
    metadata={"topic": "authentication", "intent": "question"}
)

await client.save_chat_message("session_123", message)

# Save assistant response
response = ChatMessage(
    role="assistant",
    content="We decided to use the jsonwebtoken library because...",
    metadata={"tool_calls": ["retrieve_past_decisions"]}
)

await client.save_chat_message("session_123", response)
```

### Retrieve Sessions

```python
# Get a specific session
session = await client.get_session("session_123")

if session:
    print(f"Session started: {session.started_at}")
    print(f"Project: {session.project_context}")
    print(f"Messages: {len(session.messages)}")
    
    for msg in session.messages:
        print(f"[{msg.role}] {msg.content[:50]}...")

# Get recent sessions
recent = await client.get_recent_sessions(
    limit=10,
    project_context="authentication_service"
)

for session in recent:
    print(f"{session.session_id}: {len(session.messages)} messages")
```

### Store External Resources

```python
from neuralcursor.brain.mongodb.client import ExternalResource

# Store a YouTube video
resource = ExternalResource(
    resource_id="yt_auth_tutorial_123",
    resource_type="youtube",
    title="JWT Authentication Tutorial",
    url="https://youtube.com/watch?v=...",
    content="Full transcript of the video...",
    summary="This video covers JWT implementation in Node.js, including token generation, validation, and refresh mechanisms.",
    embedding=[0.1, 0.2, ...],  # Generated by embedding model
    tags=["authentication", "jwt", "nodejs", "tutorial"],
    metadata={
        "duration": "15:30",
        "author": "Tech Channel",
        "views": 100000
    }
)

resource_id = await client.save_resource(resource)
print(f"Resource saved: {resource_id}")
```

### Search Resources

```python
# Text-based search
resources = await client.search_resources(
    query="JWT authentication",
    resource_type="youtube",
    limit=10
)

for resource in resources:
    print(f"[{resource.resource_type}] {resource.title}")
    print(f"  URL: {resource.url}")
    print(f"  Summary: {resource.summary[:100]}...")
    print(f"  Tags: {', '.join(resource.tags)}")
    print()
```

### Distillation Queue Management

```python
# Get sessions ready for distillation
sessions_to_distill = await client.get_sessions_for_distillation(
    min_messages=5  # Only sessions with 5+ messages
)

print(f"Found {len(sessions_to_distill)} sessions ready for distillation")

for session in sessions_to_distill:
    print(f"Session: {session.session_id}")
    print(f"  Messages: {len(session.messages)}")
    print(f"  Last activity: {session.last_activity}")
    
    # Process with Librarian agent
    # (see neuralcursor/agents/librarian.py)

# After distillation, mark as complete
await client.mark_session_distilled(
    session_id="session_123",
    conversation_node_uid="neo4j_node_uid_456"
)
```

## Design Patterns

### Pattern 1: Conversational Memory Capture

```python
async def capture_conversation(
    client: MongoDBClient,
    session_id: str,
    project: str,
    messages: list[dict]
) -> None:
    """
    Capture a full conversation with context.
    
    Args:
        client: MongoDB client
        session_id: Unique session identifier
        project: Project context
        messages: List of message dictionaries
    """
    for msg_data in messages:
        message = ChatMessage(
            role=msg_data["role"],
            content=msg_data["content"],
            metadata={"project": project, **msg_data.get("metadata", {})}
        )
        
        await client.save_chat_message(session_id, message)
    
    # Update session project context
    await client.db[client.config.collection_sessions].update_one(
        {"session_id": session_id},
        {"$set": {"project_context": project}}
    )
```

### Pattern 2: Resource Aggregation

```python
async def aggregate_learning_resources(
    client: MongoDBClient,
    topic: str
) -> dict:
    """
    Aggregate all resources related to a topic.
    
    Returns summary stats and top resources.
    """
    pipeline = [
        {"$match": {"tags": {"$in": [topic.lower()]}}},
        {
            "$group": {
                "_id": "$resource_type",
                "count": {"$sum": 1},
                "resources": {
                    "$push": {
                        "title": "$title",
                        "url": "$url",
                        "created_at": "$created_at"
                    }
                }
            }
        },
        {"$sort": {"count": -1}}
    ]
    
    cursor = client.db[client.config.collection_resources].aggregate(pipeline)
    results = await cursor.to_list(length=None)
    
    return {
        "topic": topic,
        "total_resources": sum(r["count"] for r in results),
        "by_type": {r["_id"]: r["count"] for r in results},
        "resources": results
    }
```

### Pattern 3: Session Analytics

```python
async def get_session_analytics(
    client: MongoDBClient,
    project_context: str | None = None
) -> dict:
    """
    Get analytics about conversation sessions.
    
    Returns message counts, active sessions, distillation status.
    """
    match_filter = {}
    if project_context:
        match_filter["project_context"] = project_context
    
    pipeline = [
        {"$match": match_filter},
        {
            "$group": {
                "_id": None,
                "total_sessions": {"$sum": 1},
                "total_messages": {"$sum": {"$size": "$messages"}},
                "distilled": {
                    "$sum": {"$cond": ["$metadata.distilled", 1, 0]}
                },
                "pending": {
                    "$sum": {"$cond": ["$metadata.distilled", 0, 1]}
                }
            }
        }
    ]
    
    cursor = client.db[client.config.collection_sessions].aggregate(pipeline)
    results = await cursor.to_list(length=1)
    
    return results[0] if results else {}
```

### Pattern 4: Hybrid Search with Embeddings

```python
async def semantic_resource_search(
    client: MongoDBClient,
    query_embedding: list[float],
    limit: int = 10
) -> list[ExternalResource]:
    """
    Perform semantic search using embeddings.
    
    Note: Requires MongoDB Atlas Vector Search index.
    """
    pipeline = [
        {
            "$vectorSearch": {
                "index": "resource_vector_index",
                "path": "embedding",
                "queryVector": query_embedding,
                "numCandidates": limit * 10,
                "limit": limit
            }
        },
        {
            "$project": {
                "resource_id": 1,
                "resource_type": 1,
                "title": 1,
                "url": 1,
                "summary": 1,
                "tags": 1,
                "score": {"$meta": "vectorSearchScore"}
            }
        }
    ]
    
    cursor = client.db[client.config.collection_resources].aggregate(pipeline)
    docs = await cursor.to_list(length=limit)
    
    return [ExternalResource(**doc) for doc in docs]
```

## Schema Design

### Sessions Collection

```javascript
{
  session_id: "session_abc123",
  project_context: "authentication_service",
  messages: [
    {
      role: "user",
      content: "How do we implement JWT?",
      timestamp: ISODate("2024-02-06T10:30:00Z"),
      metadata: { topic: "authentication" }
    },
    {
      role: "assistant",
      content: "Based on our decision...",
      timestamp: ISODate("2024-02-06T10:30:15Z"),
      metadata: { tool_calls: ["retrieve_past_decisions"] }
    }
  ],
  started_at: ISODate("2024-02-06T10:30:00Z"),
  last_activity: ISODate("2024-02-06T10:35:00Z"),
  metadata: {
    distilled: true,
    distilled_at: ISODate("2024-02-06T11:00:00Z"),
    conversation_node_uid: "neo4j_node_456"
  }
}
```

### Resources Collection

```javascript
{
  resource_id: "yt_auth_123",
  resource_type: "youtube",
  title: "JWT Authentication Tutorial",
  url: "https://youtube.com/watch?v=...",
  content: "Full transcript...",
  summary: "AI-generated summary...",
  embedding: [0.1, 0.2, 0.3, ...],  // 1536 dimensions
  tags: ["authentication", "jwt", "nodejs"],
  created_at: ISODate("2024-02-06T10:00:00Z"),
  metadata: {
    duration: "15:30",
    author: "Tech Channel",
    views: 100000
  }
}
```

### Indexes

```javascript
// Sessions
db.sessions.createIndex({ session_id: 1 }, { unique: true })
db.sessions.createIndex({ last_activity: -1 })
db.sessions.createIndex({ project_context: 1 })
db.sessions.createIndex({ "metadata.distilled": 1 })

// Resources
db.resources.createIndex({ resource_id: 1 }, { unique: true })
db.resources.createIndex({ resource_type: 1 })
db.resources.createIndex({ tags: 1 })
db.resources.createIndex({ created_at: -1 })

// Vector search (requires Atlas)
// Created via Atlas UI or API
```

## Integration with Librarian

The Librarian agent uses MongoDB as its data source:

```python
from neuralcursor.agents.librarian import LibrarianAgent
from neuralcursor.brain.neo4j.client import Neo4jClient
from neuralcursor.brain.mongodb.client import MongoDBClient

# Initialize
librarian = LibrarianAgent(neo4j_client, mongodb_client)

# Get sessions to distill
sessions = await mongodb_client.get_sessions_for_distillation(min_messages=5)

# Process each session
for session in sessions:
    # Distill into Neo4j ConversationNode
    conversation_uid = await librarian.distill_session(session)
    
    if conversation_uid:
        # Mark as complete in MongoDB
        await mongodb_client.mark_session_distilled(
            session.session_id,
            conversation_uid
        )
```

See: [../../agents/AGENTS.md](../../agents/AGENTS.md) for Librarian details.

## Performance Optimization

### Connection Pooling

Motor (async MongoDB driver) handles connection pooling automatically:

```python
# Configured in MongoDBConfig
client = AsyncIOMotorClient(
    uri,
    maxPoolSize=50,
    minPoolSize=10,
    maxIdleTimeMS=45000
)
```

### Batch Operations

```python
# Batch insert resources
resources = [resource1.model_dump(), resource2.model_dump(), ...]

await client.db[client.config.collection_resources].insert_many(
    resources,
    ordered=False  # Continue on errors
)
```

### Query Optimization

```python
# Use projections to limit data transfer
cursor = client.db[client.config.collection_sessions].find(
    {"project_context": "auth_service"},
    {"messages": 1, "_id": 0}  # Only return messages
)

# Use indexes for sort operations
cursor = cursor.sort("last_activity", -1)

# Limit results
sessions = await cursor.limit(20).to_list(length=20)
```

## Error Handling

```python
import logging
from pymongo.errors import ConnectionFailure, OperationFailure

logger = logging.getLogger(__name__)

try:
    await client.save_chat_message(session_id, message)
except ConnectionFailure as e:
    logger.exception("mongodb_connection_failed", extra={"error": str(e)})
    # Retry with exponential backoff
except OperationFailure as e:
    logger.exception("mongodb_operation_failed", extra={"code": e.code, "error": str(e)})
    raise
```

## Testing

```python
import pytest
from neuralcursor.brain.mongodb.client import MongoDBClient, MongoDBConfig, ChatMessage

@pytest.fixture
async def mongodb_client():
    """Test fixture for MongoDB client."""
    config = MongoDBConfig(
        uri="mongodb://localhost:27017",
        database="test_neuralcursor"
    )
    
    client = MongoDBClient(config)
    await client.connect()
    
    yield client
    
    # Cleanup
    await client.db.drop_collection("sessions")
    await client.db.drop_collection("resources")
    await client.close()

@pytest.mark.asyncio
async def test_save_and_retrieve_message(mongodb_client):
    """Test message save and retrieval."""
    message = ChatMessage(
        role="user",
        content="Test message"
    )
    
    await mongodb_client.save_chat_message("test_session", message)
    
    session = await mongodb_client.get_session("test_session")
    assert session is not None
    assert len(session.messages) == 1
    assert session.messages[0].content == "Test message"
```

## Related Documentation

- [client.py](./client.py) - Full client API reference
- [../AGENTS.md](../AGENTS.md) - Brain module overview
- [../../agents/AGENTS.md](../../agents/AGENTS.md) - Librarian agent usage
- [../../AGENTS.md](../../AGENTS.md) - Root documentation
